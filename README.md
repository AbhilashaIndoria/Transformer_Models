Transformer models
This repository contains notebooks to explain and train decoder only models (GPT like model), Encoder (Baby BERT), and Encoder-decoder models, The notebooks also explain preprocessing of raw text to get it ready to be used for training various models 
